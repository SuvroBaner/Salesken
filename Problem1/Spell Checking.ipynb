{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_df = pd.read_csv('../Correct_cities.csv')\n",
    "incorrect_df = pd.read_csv('../Misspelt_cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_letters = []\n",
    "for word in correct_df['name']:\n",
    "    letters = list(word)\n",
    "    for l in letters:\n",
    "        if l not in unique_letters:\n",
    "            unique_letters.append(l)\n",
    "for word in incorrect_df['misspelt_name']:\n",
    "    letters = list(word)\n",
    "    for l in letters:\n",
    "        if l not in unique_letters:\n",
    "            unique_letters.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(unique_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_letters = ''.join(sorted(unique_letters))[8:-2]\n",
    "possible_letters, len(possible_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_words_list = []\n",
    "for word in correct_df['name']:\n",
    "    correct_words_list.append(str(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building country-wise dictonary\n",
    "country_dict = {}\n",
    "correct_sorted = correct_df.sort_values(by='country')\n",
    "for i in correct_sorted.groupby('country'):\n",
    "#     print(i[1])\n",
    "    temp_df = i[1]\n",
    "    country_dict[i[0]] = list(temp_df['name'])\n",
    "#     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(correct_words_list)\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])#or known(edits3(word))\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = ' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    \n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    \n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "\n",
    "    return set(deletes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "def edits3(word):\n",
    "    return (e3 for e1 in edits1(word) for e2 in edits1(e1) for e3 in edits1(e2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction('PalqyanlCity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_ids = []\n",
    "all_corrected_names = []\n",
    "for i in tqdm(range(incorrect_df.shape[0])):\n",
    "    incorrect_name = incorrect_df.iloc[i]['misspelt_name']\n",
    "#     print(incorrect_name)\n",
    "    incorrect_country = incorrect_df.iloc[i]['country']\n",
    "#     print(incorrect_country)\n",
    "    corrected = correction(incorrect_name)\n",
    "    if  corrected in country_dict[incorrect_country]:\n",
    "        correct_city_name = corrected\n",
    "        correct_country_df = correct_df[correct_df['country']==incorrect_country]\n",
    "        correct_city_id = list(correct_country_df[correct_country_df['name']==correct_city_name]['id'])[0]\n",
    "        all_ids.append(correct_city_id)\n",
    "        all_corrected_names.append(correct_city_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_df['id'] = all_ids\n",
    "incorrect_df['correct_name'] = all_corrected_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_df.to_csv('./spell_check.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
